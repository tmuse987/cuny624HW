
---
title: 'DATA 624 Spring 2019: Project-1'
author: "Ahmed Sajjad, Harpreet Shoker, Jagruti Solao, Chad Smith, Todd Weigel"
date: "March 19, 2019"
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r set-options, echo=FALSE, cache=FALSE}
options(width = 3000)
```

```{r}
library(utils)
library('readxl')
library('xlsx')

library(tidyr)
library(dplyr)
library(ggplot2)
library(forecast)
library(fma)
library(fpp2)
library(tseries)
library(ggcorrplot)
```

#### <span style="color:red"><b><u>Overview</u></b></span>


#### <span style="color:red"><b><u>Load Dataset and Clean</u></b></span>

```{r}
project_in_df <- data.frame(read_excel("Project1data.xls", sheet = "Set for Class"))
project_in_df = mutate(project_in_df, datetime=as.Date(SeriesInd, origin="1899-12-30"))
project_in_df = project_in_df[c(1, 8, 2, 3, 4, 5, 6, 7)]

head(project_in_df)
nrow(project_in_df)

# Create separate dataframes for each group
group_S01_df = filter(project_in_df, group == 'S01')
group_S02_df = filter(project_in_df, group == 'S02')
group_S03_df = filter(project_in_df, group == 'S03')
group_S04_df = filter(project_in_df, group == 'S04')
group_S05_df = filter(project_in_df, group == 'S05')
group_S06_df = filter(project_in_df, group == 'S06')

#remove forecast cells for now

group_S01_df <- slice(group_S01_df, 1:1622) 
group_S02_df <- slice(group_S02_df, 1:1622) 
group_S03_df <- slice(group_S03_df, 1:1622) 
group_S04_df <- slice(group_S04_df, 1:1622) 
group_S05_df <- slice(group_S05_df, 1:1622) 
group_S06_df <- slice(group_S06_df, 1:1622)


#check for rows with NA's
group_S01_df[rowSums(is.na(group_S01_df))>0,]
group_S02_df[rowSums(is.na(group_S02_df))>0,]
group_S03_df[rowSums(is.na(group_S03_df))>0,]
group_S04_df[rowSums(is.na(group_S04_df))>0,]
group_S05_df[rowSums(is.na(group_S05_df))>0,]
group_S06_df[rowSums(is.na(group_S06_df))>0,]


#since we have NA's we will take the next value in sequence, e.g., if row 1600 is NA for Var01, take value from row 1601
#hopefully, since these are stock values, the value from the next day for the few missing values we have, should be close enough

#mutate them from next value
removeNAs <- function(dfTs)
{

    while(nrow(dfTs[rowSums(is.na(dfTs))>0,]) > 0)
    {           
    
        dfTs <- transmute(dfTs, 
                      SeriesInd = SeriesInd,
                      Var01 = if_else(is.na(Var01), lead(Var01), Var01),
                      Var02 = if_else(is.na(Var02), lead(Var02), Var02),
                      Var03 = if_else(is.na(Var03), lead(Var03), Var03),
                      Var05 = if_else(is.na(Var05), lead(Var05), Var05),
                      Var07 = if_else(is.na(Var07), lead(Var07), Var07))
    }
    print(dfTs[rowSums(is.na(dfTs))>0,])
    return(dfTs)
}

group_S01_df <- removeNAs(group_S01_df)
group_S02_df <- removeNAs(group_S02_df)
group_S03_df <- removeNAs(group_S03_df)
group_S04_df <- removeNAs(group_S04_df)
group_S05_df <- removeNAs(group_S05_df)
group_S06_df <- removeNAs(group_S06_df)

# Select relevant columns for each group
group_S01_df = select (group_S01_df, matches("SeriesInd|datetime|group|Var01|Var02"))
group_S02_df = select (group_S02_df, matches("SeriesInd|datetime|group|Var02|Var03"))
group_S03_df = select (group_S03_df, matches("SeriesInd|datetime|group|Var05|Var07"))
group_S04_df = select (group_S04_df, matches("SeriesInd|datetime|group|Var01|Var02"))
group_S05_df = select (group_S05_df, matches("SeriesInd|datetime|group|Var02|Var03"))
group_S06_df = select (group_S06_df, matches("SeriesInd|datetime|group|Var05|Var07"))

# Check number of rows
print (c(nrow(group_S01_df), nrow(group_S02_df), nrow(group_S03_df), nrow(group_S04_df), nrow(group_S05_df), nrow(group_S06_df)))

# Verify dataframes
head(project_in_df, 20)
head(group_S01_df, 20)
head(group_S02_df, 20)
head(group_S03_df, 20)
head(group_S04_df, 20)
head(group_S05_df, 20)
head(group_S06_df, 20)
```

#### <span style="color:red"><b><u>Exploratory Data Analysis</u></b></span>
```{r}
```

#### <span style="color:red"><b><u>Cleanup Dataset</u></b></span>


#### <span style="color:red"><b><u>Build Model</u></b></span>


#### <span style="color:red"><b><u>Evaluate Model</u></b></span>


#### <span style="color:red"><b><u>Group S01 Forecast</u></b></span>
#### <span style="color:red"><b><u>Group S02 Forecast</u></b></span>
#### <span style="color:red"><b><u>Group S03 Forecast</u></b></span>
#### <span style="color:red"><b><u>Group S04 Forecast</u></b></span>
#### <span style="color:red"><b><u>Group S05 Forecast</u></b></span>

###This Section is using ARIMA for now.

First let's get the dataframe data into a timeseries for variable 02.
The data is stored as a series of dates, 5 days with a break after, so essentially 52 weeks times 5 days will divide it up nicely into 7 years of data.  We will then fit the data using auto.arima to find the appropriate values for P,D,Q (p = the number of lag observations, d = degree of differencing, and q = size of the moving average window, for lagged forecast errors ).

We see that a 1,1,3 model appears to be most appropriate.

```{r}
library(astsa)
h <- 140
TsVar02 <- ts(group_S05_df$Var02, frequency = 5*52)

arimaFitVar02 <- auto.arima(TsVar02, seasonal = FALSE)
arimaFitVar02

```
We will use the package Applied Statistical Time Series Analysis (astsa) and it's wrapper module, sarima around the arima set of tools to do our forecasting.

Looking at the residuals from the package output, we see that they look like white noise, which is what we hope, as we don't wish to see a pattern.  The ACF of the residuals look acceptable too.  There are a couple of small spikes just above the threshold of significance, but otherwise fine.

Note the box test results show that there may still be correlation on the residuals as the 
```{r}
sarima(TsVar02, 1, 1, 3)

fSarima <- sarima.for(TsVar02[1:1622], 140, 1, 1, 3, plot.all = TRUE)
fSarima$pred[1:20]
#save prediction into df
group_S05_df[1623:1762,2] <- fSarima$pred

```

###ARIMA Fit for Var03
Doing the same process for Var03, we see that a 2,1,1 model is best.

```{r}
library(astsa)
h <- 140
TsVar03 <- ts(group_S05_df$Var03, frequency = 5*52)

arimaFitVar03 <- auto.arima(TsVar03, seasonal = FALSE)
arimaFitVar03

```

```{r}
fitArimaV03 <- sarima(TsVar03, 2, 1, 1, details = FALSE)

 
##for some  reason this blows up if in ts with frequency of 260
fSarima <- sarima.for(TsVar03[1:1622], n.ahead = 140, 2, 1, 1)
fSarima$pred[1:20]
#save prediction into df
group_S05_df[1623:1762,3] <- fSarima$pred
```

###Attempted a box cox transform to see how that worked out, really other than scale is pretty similar
```{r}
bcTsVar02 <- BoxCox(TsVar02, lambda = "auto")
fSarima <- sarima.for(bcTsVar02, 140, 1, 1, 3)

```

####Sanity checks for differencing.  Run some difference tests, we see that one difference is absolutely needed, and perhaps two differences could be warranted for var03 as one order of difference gives .07 value for the test statistic (i.e.it is greater than .05), but it is questionable, as extra differencing in itself can lead to errors.

```{r}
#Reset values
TsVar02 <- ts(group_S05_df$Var02, frequency = 5*52)
TsVar03 <- ts(group_S05_df$Var03, frequency = 5*52)

library(urca)
summary(ur.kpss(TsVar02))
summary(ur.kpss(diff(TsVar02)))

summary(ur.kpss(TsVar03))
summary(ur.kpss(diff(TsVar03)))
print("Do we actually need a second order of differencing?")
summary(ur.kpss(diff(diff(TsVar03))))

print("Checking for seasonality:")
nsdiffs(TsVar02, test = "seas")
nsdiffs(TsVar03, test = "seas")
```
Checking ACF grapsh for the p and q values.

```{r}
#113
Acf(diff(TsVar02))
pacf(diff(TsVar02))
Acf(diff(TsVar03))
pacf(diff(TsVar03))
```
Looking at the plots is seems like a (1,1,4) model might be better for Var02 considering the number of spikes in the acf graph.  Rerunning using that model, the box test results look better, althought the AIC numbers are virtually unchanged.

The 2,1,1 based on the acf graphs looks reasonable for Var03.
```{r}
sarima(TsVar02, 4, 1, 4)
sarima.for(TsVar02, 140, 4, 1,4)
```


#### <span style="color:red"><b><u>Group S06 Forecast</u></b></span>


#### <span style="color:red"><b><u>Export Results</u></b></span>
```{r}
write.xlsx(project_in_df, file = "output.xls", sheetName = "Set for Class", row.names=FALSE, append = FALSE)
write.xlsx(group_S01_df, file = "output.xls", sheetName = "S01", row.names=FALSE, append = TRUE)
write.xlsx(group_S02_df, file = "output.xls", sheetName = "S02", row.names=FALSE, append = TRUE)
write.xlsx(group_S03_df, file = "output.xls", sheetName = "S03", row.names=FALSE, append = TRUE)
write.xlsx(group_S04_df, file = "output.xls", sheetName = "S04", row.names=FALSE, append = TRUE)
write.xlsx(group_S05_df, file = "output.xls", sheetName = "S05", row.names=FALSE, append = TRUE)
write.xlsx(group_S06_df, file = "output.xls", sheetName = "S06", row.names=FALSE, append = TRUE)

```

#### <span style="color:red"><b><u>Conclusion</u></b></span>

#### <span style="color:red"><b><u>References</u></b></span>


